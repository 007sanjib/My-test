{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Demo2_Payment_Reconciliation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/007sanjib/My-test/blob/master/Demo2_Payment_Reconciliation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iD2e7YYIolyI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c212aab5-b99c-41e2-a63b-e6c987c529d2"
      },
      "source": [
        "!pip install lexnlp\n",
        "!pip install panda\n",
        "!pip install numpy\n",
        "\n",
        "!pip install spacy\n",
        "!pip install daterangeparser\n",
        "!pip install nltk\n",
        "!pip install pandas\n",
        "!pip install ordereddict\n",
        "!pip install nb-black\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lexnlp\n",
            "  Downloading lexnlp-2.0.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.0 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting dateparser==0.7.2\n",
            "  Downloading dateparser-0.7.2-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 34.1 MB/s \n",
            "\u001b[?25hCollecting nltk==3.5\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 56.3 MB/s \n",
            "\u001b[?25hCollecting requests==2.24.0\n",
            "  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 279 kB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.23.1\n",
            "  Downloading scikit_learn-0.23.1-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 6.5 MB/s \n",
            "\u001b[?25hCollecting us==2.0.2\n",
            "  Downloading us-2.0.2.tar.gz (14 kB)\n",
            "Collecting reporters-db==2.0.3\n",
            "  Downloading reporters_db-2.0.3-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[K     |████████████████████████████████| 72 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting numpy==1.19.1\n",
            "  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.5 MB 7.6 kB/s \n",
            "\u001b[?25hCollecting joblib==0.14.0\n",
            "  Downloading joblib-0.14.0-py2.py3-none-any.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 66.2 MB/s \n",
            "\u001b[?25hCollecting regex==2020.11.13\n",
            "  Downloading regex-2020.11.13-cp37-cp37m-manylinux2014_x86_64.whl (719 kB)\n",
            "\u001b[K     |████████████████████████████████| 719 kB 65.4 MB/s \n",
            "\u001b[?25hCollecting pandas==1.1.3\n",
            "  Downloading pandas-1.1.3-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.5 MB 18.9 MB/s \n",
            "\u001b[?25hCollecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 78 kB/s \n",
            "\u001b[?25hCollecting num2words==0.5.10\n",
            "  Downloading num2words-0.5.10-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 9.9 MB/s \n",
            "\u001b[?25hCollecting pycountry==20.7.3\n",
            "  Downloading pycountry-20.7.3.tar.gz (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 13.4 MB/s \n",
            "\u001b[?25hCollecting scipy==1.5.1\n",
            "  Downloading scipy-1.5.1-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 80 kB/s \n",
            "\u001b[?25hCollecting datefinder-lexpredict==0.6.2.1\n",
            "  Downloading datefinder_lexpredict-0.6.2.1-py2.py3-none-any.whl (8.0 kB)\n",
            "Collecting Unidecode==1.1.1\n",
            "  Downloading Unidecode-1.1.1-py2.py3-none-any.whl (238 kB)\n",
            "\u001b[K     |████████████████████████████████| 238 kB 70.1 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of <Python from Requires-Python> to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of lexnlp to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting lexnlp\n",
            "  Downloading lexnlp-1.8.0-py3-none-any.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 10.8 MB/s \n",
            "\u001b[?25hCollecting pandas==0.24.2\n",
            "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 42.3 MB/s \n",
            "\u001b[?25hCollecting regex==2020.7.14\n",
            "  Downloading regex-2020.7.14-cp37-cp37m-manylinux2010_x86_64.whl (660 kB)\n",
            "\u001b[K     |████████████████████████████████| 660 kB 47.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.4.2 in /usr/local/lib/python3.7/dist-packages (from datefinder-lexpredict==0.6.2.1->lexnlp) (2.8.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from datefinder-lexpredict==0.6.2.1->lexnlp) (2018.9)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from dateparser==0.7.2->lexnlp) (1.5.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->lexnlp) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->lexnlp) (5.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->lexnlp) (4.62.0)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.7/dist-packages (from num2words==0.5.10->lexnlp) (0.6.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.24.0->lexnlp) (2.10)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Collecting jellyfish==0.6.1\n",
            "  Downloading jellyfish-0.6.1.tar.gz (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 46.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: nltk, pycountry, us, jellyfish\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434689 sha256=20456b6075d59d84f9247c0230b3b4a8fe81062368adf014f1082c5408b5c445\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
            "  Building wheel for pycountry (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycountry: filename=pycountry-20.7.3-py2.py3-none-any.whl size=10746883 sha256=6cacd7d38d1bbccaf56e560adaaf44fab30eeb6649e541fc0f6c1cdf93702c25\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/e8/3f/120ccc1ff7541c108bc5d656e2a14c39da0d824653b62284c6\n",
            "  Building wheel for us (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for us: filename=us-2.0.2-py3-none-any.whl size=11942 sha256=00b3b7dab7cb494bab292a6599ea91d7c8a9e749cf6fb88ad39650ab036a5bf9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/6b/11/cda9ea2438f721330a35c9a2c8e34b4aedcd34c89af48a4d00\n",
            "  Building wheel for jellyfish (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jellyfish: filename=jellyfish-0.6.1-cp37-cp37m-linux_x86_64.whl size=72172 sha256=ffdceed9c7a72c894333136a8b8b2b532484366c6efba08f00b4eb03c743e3e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/99/51/7de469e37cd1b3c763c24394e1ebf1baa2d79e094bf346cf80\n",
            "Successfully built nltk pycountry us jellyfish\n",
            "Installing collected packages: numpy, threadpoolctl, scipy, regex, joblib, jellyfish, us, Unidecode, scikit-learn, requests, reporters-db, pycountry, pandas, num2words, nltk, gensim, dateparser, datefinder-lexpredict, lexnlp\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray 0.18.2 requires pandas>=1.0, but you have pandas 0.24.2 which is incompatible.\n",
            "tensorflow 2.6.0 requires numpy~=1.19.2, but you have numpy 1.19.1 which is incompatible.\n",
            "plotnine 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "mizani 0.6.0 requires pandas>=0.25.0, but you have pandas 0.24.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 0.24.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.24.0 which is incompatible.\n",
            "fbprophet 0.7.1 requires pandas>=1.0.4, but you have pandas 0.24.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Unidecode-1.1.1 datefinder-lexpredict-0.6.2.1 dateparser-0.7.2 gensim-3.8.3 jellyfish-0.6.1 joblib-0.14.0 lexnlp-1.8.0 nltk-3.5 num2words-0.5.10 numpy-1.19.1 pandas-0.24.2 pycountry-20.7.3 regex-2020.7.14 reporters-db-2.0.3 requests-2.24.0 scikit-learn-0.23.1 scipy-1.5.1 threadpoolctl-2.2.0 us-2.0.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting panda\n",
            "  Downloading panda-0.3.1.tar.gz (5.8 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from panda) (57.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from panda) (2.24.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->panda) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->panda) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->panda) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->panda) (2.10)\n",
            "Building wheels for collected packages: panda\n",
            "  Building wheel for panda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for panda: filename=panda-0.3.1-py3-none-any.whl size=7255 sha256=2ac42fa13325cc9980900b8bec1e7c1091643174a46f049137a7c0b6cbf6a772\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/3d/81/a3665ce657d35359ca337b1db2975dbe5cd281a88b8982f6b6\n",
            "Successfully built panda\n",
            "Installing collected packages: panda\n",
            "Successfully installed panda-0.3.1\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.24.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.6.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Collecting daterangeparser\n",
            "  Downloading DateRangeParser-1.3.2-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from daterangeparser) (2.4.7)\n",
            "Installing collected packages: daterangeparser\n",
            "Successfully installed daterangeparser-1.3.2\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk) (2020.7.14)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk) (0.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk) (4.62.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (0.24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.5.0->pandas) (1.15.0)\n",
            "Collecting ordereddict\n",
            "  Downloading ordereddict-1.1.tar.gz (2.1 kB)\n",
            "Building wheels for collected packages: ordereddict\n",
            "  Building wheel for ordereddict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ordereddict: filename=ordereddict-1.1-py3-none-any.whl size=3552 sha256=8693faea10502ab0cf7c3f6bc1edce1b26713c263255b793d648166490ead1b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ca/c3/78f1fe551cb748c3dc60e50b60c87febf00a3ffebd8c4e7094\n",
            "Successfully built ordereddict\n",
            "Installing collected packages: ordereddict\n",
            "Successfully installed ordereddict-1.1\n",
            "Collecting nb-black\n",
            "  Downloading nb_black-1.0.7.tar.gz (4.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from nb-black) (5.5.0)\n",
            "Collecting black>='19.3'\n",
            "  Downloading black-21.7b0-py3-none-any.whl (141 kB)\n",
            "\u001b[K     |████████████████████████████████| 141 kB 5.0 MB/s \n",
            "\u001b[?25hCollecting typed-ast>=1.4.2\n",
            "  Downloading typed_ast-1.4.3-cp37-cp37m-manylinux1_x86_64.whl (743 kB)\n",
            "\u001b[K     |████████████████████████████████| 743 kB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (7.1.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (1.4.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (3.7.4.3)\n",
            "Requirement already satisfied: tomli<2.0.0,>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (1.2.1)\n",
            "Collecting mypy-extensions>=0.4.3\n",
            "  Downloading mypy_extensions-0.4.3-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black>='19.3'->nb-black) (2020.7.14)\n",
            "Collecting pathspec<1,>=0.8.1\n",
            "  Downloading pathspec-0.9.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (4.4.2)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (57.4.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->nb-black) (2.6.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->nb-black) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->nb-black) (1.15.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->nb-black) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->nb-black) (0.7.0)\n",
            "Building wheels for collected packages: nb-black\n",
            "  Building wheel for nb-black (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nb-black: filename=nb_black-1.0.7-py3-none-any.whl size=5298 sha256=597fb4eb0ff831c9bc7584ff86f2aeae69b10a4321c84804e10d60b96381d7d6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/b2/88/51c66d23ea5fd0d40ed50997555e15d981d92671376a9a412a\n",
            "Successfully built nb-black\n",
            "Installing collected packages: typed-ast, pathspec, mypy-extensions, black, nb-black\n",
            "Successfully installed black-21.7b0 mypy-extensions-0.4.3 nb-black-1.0.7 pathspec-0.9.0 typed-ast-1.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG7ywNtqlmDT",
        "outputId": "a62c0a2a-cdaa-46b6-8c4b-f6bf737ce923"
      },
      "source": [
        "!python --version\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.7.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glYFhzRuotFL",
        "outputId": "9fcf3af4-e4a1-4bbf-da85-4bcb538bf589"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY9anGLpry7a",
        "outputId": "7f3c0925-e8e8-4dda-aac4-8b206ae44614"
      },
      "source": [
        "%ls \"/content/drive/MyDrive/Banking-Solutions/B2B-Payment\"\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample-1-pacs-008.xml  Sample-3-pacs-008.xml  Sample-5-pacs-008.xml\n",
            "Sample-2-pacs-008.xml  Sample-4-pacs-008.xml  Sample-6-pacs-008.xml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpyl6MBjsSRo"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuTmNoIUotIN"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5cy6DdSotKi"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfJhs_WaZevA",
        "outputId": "5535b997-f303-4ad2-e215-889135552358"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import re\n",
        "\n",
        "import spacy\n",
        "import requests\n",
        "import re\n",
        "import IPython\n",
        "from daterangeparser import parse\n",
        "from collections import OrderedDict\n",
        "\n",
        "import operator\n",
        "import glob, os\n",
        "import pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "import codecs\n",
        "import re\n",
        "import json\n",
        "import copy \n",
        "from dateutil.parser import parse\n",
        "import nltk\n",
        "\n",
        "# import lexnlp.extract.en.tokens\n",
        "import lexnlp.extract.en.money\n",
        "import lexnlp.extract.en.en_language_tokens\n",
        "import lexnlp.extract.en.entities.nltk_re\n",
        "import lexnlp.extract.en.amounts\n",
        "import lexnlp.extract.en.dates\n",
        "import lexnlp.extract.en.geoentities\n",
        "import lexnlp.extract.en.entities\n",
        "import lexnlp.extract.en.percents\n",
        "import lexnlp.extract.en.pii\n",
        "import lexnlp.extract.en.urls\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import xml.etree.ElementTree as et\n",
        "import os\n",
        "from pathlib import Path\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vWzAYtCwe8X"
      },
      "source": [
        "\n",
        "\n",
        "pd.set_option('display.max_colwidth', 999) # prints the DataFrame cells with full text, none of its values truncated.\n",
        "pd.set_option('display.max_columns', 100) # prints upto 100 columns\n",
        "pd.set_option('display.max_rows', 200) # prints upto 200 rows\n",
        "pd.set_option('display.colheader_justify', 'left') # dataframe column header left justified\n",
        "\n",
        "pd.options.display.float_format = (\n",
        "    \"{:,.4f}\".format\n",
        ")  # format upto 4 decimals of float numbers\n",
        "\n",
        "# python code style\n",
        "# %load_ext nb_black"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4t3V0aKuyGlA"
      },
      "source": [
        "# Class to parse untructured payement (credit transfer) infomation and transform into structured JSON\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXy5cLICyVRR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "502fdd9e-8a06-4783-93af-2030b8c48018"
      },
      "source": [
        "\"\"\"\n",
        "  Following format of dates are parsed\n",
        "\n",
        "  date_array = [\n",
        "    '2018-06-29 08:15:27.243860',\n",
        "    'Jun 28 2018 7:40AM',\n",
        "    'Jun 28 2018 at 7:40AM',\n",
        "    'September 18, 2017, 22:19:55',\n",
        "    'Sun, 05/12/1999, 12:30PM',\n",
        "    'Mon, 21 March, 2015',\n",
        "    '2018-03-12T10:12:45Z',\n",
        "    '2018-06-29 17:08:00.586525+00:00',\n",
        "    '2018-06-29 17:08:00.586525+05:00',\n",
        "    'Tuesday , 6th September, 2017 at 4:30pm',\n",
        "    # '46373892034012' # NOT A DATE\n",
        "  ]\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n  Following format of dates are parsed\\n\\n  date_array = [\\n    '2018-06-29 08:15:27.243860',\\n    'Jun 28 2018 7:40AM',\\n    'Jun 28 2018 at 7:40AM',\\n    'September 18, 2017, 22:19:55',\\n    'Sun, 05/12/1999, 12:30PM',\\n    'Mon, 21 March, 2015',\\n    '2018-03-12T10:12:45Z',\\n    '2018-06-29 17:08:00.586525+00:00',\\n    '2018-06-29 17:08:00.586525+05:00',\\n    'Tuesday , 6th September, 2017 at 4:30pm',\\n    # '46373892034012' # NOT A DATE\\n  ]\\n\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYCQ_nvipCqf"
      },
      "source": [
        "class CreditTransferTextParserNLP:\n",
        "\n",
        "    def __init__(self):\n",
        "      self.__imp_keywords_synonyms = \\\n",
        "      { \n",
        "        \"invoice\" : [\"invoice\", \"inv\", \"bill\", \"inv.\",\n",
        "                     \"inv#\", \"Invoice#\", \"rmtid\", \"remit\", \"rmt\"],\n",
        "        \"account\" : [\"account\", \"a/c\", \"account.\", \"a/c.\", \"act\", \"act.\"],\n",
        "        \"number\" : [\"number\", \"no.\", \"#\", \"num\", \"number:\"],\n",
        "        \"reference\" : [\"reference\", \"ref\", \"ref.\",\"ref#\", \n",
        "                      \"refnum\", \"reference.\", \"reference#\"],\n",
        "        \"from\" : [\"from\"],\n",
        "        \"to\" : [\"to\"],\n",
        "        \"tax\" : [\"tax\",\"local tax\", \"taxing\", \"taxed\"],\n",
        "        \"fee\" : [\"fee\",\"fees\", \"charge\", \"chg\"],\n",
        "        \"discount\" : [\"discount\", \"dscnt\"],\n",
        "        \"partial\" : [\"partial\", \"part\", \"partially\"],\n",
        "        \"full\" : [\"full\",\"fully\"],\n",
        "        # identify bank as a keyword, not organization \n",
        "        \"bank\" : [\"bank\", \"depository financial institution\",\n",
        "                  \"financial institution\"],\n",
        "        \"credit\" : [\"credit\", \"credit note\", \"crdt\", \"cren\"],\n",
        "        \"debit\" : [\"debit\", \"debit note\", \"dbit\", \"debn\"],\n",
        "        \"due\" : [\"due\", \"duepyblamt\", ],\n",
        "        \"share\" : [\"shared\", \"share\", \"sharing\"]\n",
        "      }\n",
        "    # end of constructor  \n",
        "\n",
        "\n",
        "    def __extract_entities_spacy(self,\n",
        "                                 str_param):\n",
        "        \"\"\"\n",
        "          Description : identify all entities\n",
        "          Parameters : \n",
        "            str_param : the full string \n",
        "          Return : Dictionary of all entities\n",
        "        \"\"\"\n",
        "        nlp = spacy.load(\"en_core_web_sm\")\n",
        "        doc = nlp(str_param)\n",
        "  \n",
        "        \n",
        "        # ent_dict_list = []\n",
        "        # for ent in doc.ents:\n",
        "        #   ent_dict = {}\n",
        "        #   # print(\"{} : {}\".format(ent.text,ent.label_))\n",
        "        #   ent_dict[ent.text] = ent.label_\n",
        "        #   # ent_dict[\"start\"] = ent.start \n",
        "        #   # ent_dict[\"end\"] = ent.end\n",
        "        #   # ent_dict[\"span\"] = doc[ent.start:ent.end]  # The matched span\n",
        "        #   # print(\"SPACY:\", ent.start  , ent.end)\n",
        "        #   ent_dict_list.append(ent_dict)\n",
        "\n",
        "        ent_dict_list = [{ent.text:ent.label_}  for ent in doc.ents ]  \n",
        "            \n",
        "\n",
        "          # len(doc.ents)\n",
        "        # print(\"ENT list\", ent_dict_list)\n",
        "          # sorted_entities_spacy = dict(sorted(ent_dict.items(), \n",
        "          #                           key=lambda x: x[1], reverse=False))\n",
        "                                              # key=operator.itemgetter(1)))\n",
        "          # print(\"SPACY sorted entities\", sorted_entities_spacy)\n",
        "          # return sorted_entities_spacy\n",
        "        return ent_dict_list\n",
        "\n",
        "\n",
        "    def __identify_special_keywords(self,\n",
        "                                    str_param : str, \n",
        "                                    # exception_list : list\n",
        "                                    ):\n",
        "      \"\"\"\n",
        "        Description : identify all important keywords,\n",
        "                      Uses NLP to create intermediate JSON\n",
        "        Parameters : \n",
        "          str_param : the full string \n",
        "        Return : Dictionary of all keywords, IDs\n",
        "      \"\"\"\n",
        "      \n",
        "      # nouns = list(lexnlp.nlp.en.tokens.get_nouns(str_param, \n",
        "      #                                             lemmatize=True))\n",
        "      tokens_list = lexnlp.nlp.en.tokens.get_token_list(str_param)\n",
        "\n",
        "      # print(\"|||| \",tokens_list)\n",
        "\n",
        "      dict_keywords = {}\n",
        "      # position = 0\n",
        "\n",
        "      # nn = nouns\n",
        "      # nn.append(\"A/C\")\n",
        "\n",
        "      # identify important keywords\n",
        "      for n in tokens_list:\n",
        "        # print(\"* match\", n)\n",
        "        for keyword_i in self.__imp_keywords_synonyms:\n",
        "          # print( n.lower())\n",
        "          if n.lower() in self.__imp_keywords_synonyms[keyword_i]:\n",
        "            # print(\"*** found match \", n)\n",
        "            position = str_param.find(n)\n",
        "            dict_keywords[position] = keyword_i\n",
        "\n",
        "        # position = position + len(n)   \n",
        "\n",
        "      # print(\"$$ \", dict_keywords)                  \n",
        "\n",
        "      # Identify ID, contains nummeric(atleast one) and char\n",
        "      nouns_with_num = [i  for i in tokens_list if \n",
        "          \"{}\".format(i).isalpha() == False and \n",
        "          any(chr.isdigit() for chr in \"{}\".format(i))]\n",
        "          # any(map(str.isdigit, str(i))) ]  \n",
        "      # print(\"Nouns with numbers:\", nouns_with_num)\n",
        "\n",
        "      # No \".\", Minimum length is 5, contains atleast a digit  \n",
        "      nouns_with_num_no_dot = [i for i in nouns_with_num if \".\" not \n",
        "        in \"{}\".format(i) and len(\"{}\".format(i)) >= 4 ]\n",
        "      # print(\"ID s:\", nouns_with_num_no_dot)\n",
        "\n",
        "      id_dict = {}\n",
        "      for n in nouns_with_num_no_dot: \n",
        "        id_dict[str_param.find(\"{}\".format(n))] = \"{}\".format(n)\n",
        "\n",
        "      if id_dict : \n",
        "        # print(\"*****\", sorted(id_dict.keys()))\n",
        "        dict_keywords[\"ID\"] = id_dict\n",
        "\n",
        "\n",
        "      dict_keywords\n",
        "\n",
        "      return dict_keywords\n",
        "\n",
        "\n",
        "\n",
        "    def __identify_all_keywords(self,\n",
        "                                str_param):\n",
        "      \"\"\"\n",
        "        Description : identify all important keywords\n",
        "        Parameters : \n",
        "          str_param : the full string \n",
        "        Return : Dictionary of all keywords\n",
        "      \"\"\"\n",
        "\n",
        "      # print(\"Inside identify_all_keywords(): Length of text =\",\n",
        "      #       len(str_param))  \n",
        "\n",
        "      if (not(str_param) or \n",
        "          len(str_param) == 0 or \n",
        "          len(str_param.strip()) ==0 ): \n",
        "            return np.nan\n",
        "\n",
        "      # Firstly identify money\n",
        "      money_dict_list = []\n",
        "      ls_money = list(lexnlp.extract.en.money.get_money(str_param))\n",
        "      # print(\"Money:\", ls_money)\n",
        "      ## DETERMINE POSITION SO THAT RELATED ENTITY CAN BE FOUND\n",
        "      for dec,cur in ls_money:\n",
        "        pos = str_param.find(\"{}\".format(dec))\n",
        "        if pos <0 : # position not found \n",
        "          pos = str_param.find(\"{}\".format(int(dec)))\n",
        "          if pos <0 : # position not found \n",
        "            pos = str_param.find(cur)\n",
        "\n",
        "        money_dict_list.append( {\n",
        "                        \"amount\":float(dec), \n",
        "                        \"currency\":cur,\n",
        "                        \"position\" : pos\n",
        "                        } )\n",
        "        #end of for loop\n",
        "\n",
        "      return_dict = {\"Money\": money_dict_list }\n",
        "\n",
        "      #identify contact : phone, name, ssn etc.\n",
        "      ls_pii = list(lexnlp.extract.en.pii.get_pii(text=str_param))\n",
        "      # print(\"PII\", ls_pii)\n",
        "      # print(\"PII tranformed:\", [{key:val} for key,val in ls_pii])\n",
        "      return_dict[\"Contacts\"] = [{k:v} for k,v in ls_pii]\n",
        "\n",
        "      # remove the identified text so that it wont be treated as ID \n",
        "      # or another entity\n",
        "      for cont in return_dict[\"Contacts\"]:\n",
        "          \n",
        "          try:\n",
        "            ph = cont[\"us_phone\"]\n",
        "            if ph:\n",
        "              if str_param.find(ph) >= 0 :\n",
        "                str_param =  str_param.replace(ph,\"\",1)\n",
        "              else: # phone is in format 888-888-8888\n",
        "                ph = ph.replace(\"(\",\"\",1)\n",
        "                ph = ph.replace(\")\",\"\",1)\n",
        "                ph = ph.replace(\" \",\"-\",1)\n",
        "                # print(\"Transformed phone number\", ph)\n",
        "                str_param =  str_param.replace(ph,\"\",1)\n",
        "          except:\n",
        "            pass    \n",
        "\n",
        "      # print(\"*** str_param\", str_param)\n",
        "      ls_urls = list(lexnlp.extract.en.urls.get_urls(text=str_param))\n",
        "      return_dict[\"URLs\"] = ls_urls\n",
        "      # print(\"*** return_dict\", return_dict[\"URLs\"])\n",
        "\n",
        "\n",
        "      # Next identify percents and rates\n",
        "      # print(\"PERCENTS AND RATES:\",\n",
        "      ls_percents = list(lexnlp.extract.en.percents.get_percents(\n",
        "          text=str_param))\n",
        "      # print(\"Percents & Rates\", ls_percents)\n",
        "      percent_dict = [{\"type\":str_percent, \"value\":float(dec),\n",
        "                      \"position\" : str_param.find(str_percent)} \\\n",
        "        for (str_percent,dec,dec_transformed) in ls_percents ] \n",
        "\n",
        "      return_dict[\"Percents_Rates\"] = percent_dict \n",
        "\n",
        "\n",
        "      # Use SPACY\n",
        "      entities_spacy = self.__extract_entities_spacy(str_param) \n",
        "\n",
        "      #Next identify date\n",
        "      # date_dict = {s:key for (key,value,s,e) in \n",
        "      #         entities_spacy.items() if value == \"DATE\"} # no duplicates\n",
        "      # # print(\"DATES : \", date_dict)        \n",
        "      # return_dict[\"Dates\"] = date_dict\n",
        "      \n",
        "      date_dict = {}\n",
        "      company_dict = {}\n",
        "      bank_dict = {}\n",
        "      location_dict = {}\n",
        "      \n",
        "      for ent in entities_spacy:\n",
        "        start = -1\n",
        "        # length = 0\n",
        "        # end = 0\n",
        "        # found_entity=False\n",
        "        # found_key = None\n",
        "        # found_value = None\n",
        "        \n",
        "        for key,value in ent.items():\n",
        "\n",
        "        #   if value in [\"DATE\", \"ORG\", \"GPE\"]:\n",
        "        #     found_entity = True\n",
        "        #     found_key = key\n",
        "        #     found_value = value\n",
        "\n",
        "            \n",
        "        #   if found_entity == True:\n",
        "        #      if key == \"start\":\n",
        "        #       start = value\n",
        "        #      elif key == \"end\":\n",
        "        #       end = value   \n",
        "\n",
        "        #    # enfd of for loop   \n",
        "\n",
        "        # if found_entity == True:    \n",
        "\n",
        "          if value == \"DATE\":\n",
        "            start = str_param.find(key)\n",
        "            # length = len(key)\n",
        "            date_dict[start] = key\n",
        "            if key.isnumeric() : #it can be a ID\n",
        "            # and \\\n",
        "            # int(key) <1900 and int(key)>2100 : #it can be a ID\n",
        "                start = -1\n",
        "            # found_entity=True\n",
        "            \n",
        "          elif value == \"ORG\" :\n",
        "            # currenecy are recognized as ORG by SPACY\n",
        "            if key.upper() not in \\\n",
        "            [i[\"currency\"] for i in return_dict[\"Money\"]]:\n",
        "              start = str_param.find(key)\n",
        "              # length = len(key)\n",
        "              # found_entity=True\n",
        "              if \"bank\" in key.lower():\n",
        "                bank_dict[start] = key\n",
        "              else:  \n",
        "                company_dict[start] = key\n",
        "\n",
        "            start = -1 # Bank names may be useful to relate entity \n",
        "          elif value == \"GPE\":\n",
        "            start = str_param.find(key)\n",
        "            # length = len(key)\n",
        "            # found_entity=True\n",
        "            location_dict[start] = key\n",
        "\n",
        "          # remove so that they wont be identified as ID, entities\n",
        "          # print(\"str_param\",str_param[:start], str_param[start+length:])\n",
        "          # str_param = str_param[:start] + str_param[start+length:]\n",
        "\n",
        "          if start >= 0:\n",
        "            str_param = str_param.replace(key, \" \"*len(key),1)\n",
        "\n",
        "\n",
        "\n",
        "      return_dict[\"Dates\"] = date_dict    \n",
        "\n",
        "      company_dict[\"Banks\"] = bank_dict\n",
        "\n",
        "      return_dict[\"Companies\"] = company_dict\n",
        "\n",
        "      return_dict[\"Locations\"] = location_dict   \n",
        "\n",
        "      # print(\"after SPACY, return_dict\", return_dict)\n",
        "\n",
        "      #Next identify numbers\n",
        "      ls_decimals = list(lexnlp.extract.en.amounts.get_amounts(str_param))\n",
        "      # print(\"All Decimals :\",ls_decimals)\n",
        "      return_dict[\"Numerics\"] = [{str_param.find( \n",
        "            \"{}\".format(int(i)) ) :float(i)} for i in ls_decimals]\n",
        "\n",
        "      # Next identify Companies\n",
        "      # company_list = list(\n",
        "      #     lexnlp.extract.en.entities.nltk_re.get_companies(example))\n",
        "      # Use spacy\n",
        "      # company_dict = {str_param.find(key):key for (key,value,s,e) in \n",
        "      #         entities_spacy.items() if value == \"ORG\" and key not\n",
        "      #         in [i[\"currency\"] for i in return_dict[\"Money\"]]} \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      # # print(\"ALL COMPANIES :\",company_dict)\n",
        "      # bank_dict = {str_param.find(key):key for (pos,key) in \n",
        "      #             company_dict.items() if key.lower().find(\"bank\") >= 0}   \n",
        "      # # print(\"ALL BANKS :\",bank_dict)\n",
        "\n",
        "      # company_dict = {str_param.find(key):key for (pos,key) in \n",
        "      #             company_dict.items() if key.lower().find(\"bank\") < 0}\n",
        "      # # print(\"SHORTLIST ORG :\",company_dict)              \n",
        "\n",
        "      # company_dict[\"Banks\"] = bank_dict\n",
        "      # # print(company_dict)\n",
        "\n",
        "      # # return_dict[\"Bank\"] = bank_dict\n",
        "      # return_dict[\"Companies\"] = company_dict\n",
        "\n",
        "      # Next identity geo locations\n",
        "      # location_dict = {str_param.find(key):key for (key,value,s,e) in \n",
        "      #         entities_spacy.items() if value == \"GPE\"}\n",
        "      # # print(\"Locations : \", location_dict)     \n",
        "      # return_dict[\"Locations\"] = location_dict   \n",
        "\n",
        "      # Next identify important keywords \n",
        "      return_dict[\"Keywords\"] = self.__identify_special_keywords(\n",
        "                                                        str_param) \n",
        "\n",
        "      return return_dict\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __find_locations(self,\n",
        "                      position_param : int,\n",
        "                      str_param : str, \n",
        "                      dict_param : dict):\n",
        "      \n",
        "      \"\"\"\n",
        "        Description:\n",
        "            Search nearby geo-location enity on the left side\n",
        "        Paramter:\n",
        "            position_param : int = position of main entity\n",
        "            str_param : str = main enity\n",
        "            dict_param : dict = position and entity combination      \n",
        "        returns : Dict of one entity, with prepositions\n",
        "          Returns : \n",
        "            String : closet location enity on right side, upto 10 characters\n",
        "                    of search lenght, returns \"\" if not found    \n",
        "      \"\"\"\n",
        "      return_str= \"\"\n",
        "\n",
        "      all_locations = dict_param[\"Locations\"]\n",
        "\n",
        "      # search right side\n",
        "      for pos, val in all_locations.items():\n",
        "        # print(\"LOC : pos\",pos)\n",
        "        # print(\"LOC : position_param\",position_param)\n",
        "        # print(\"LOC : len(str_param)\",len(str_param))\n",
        "        # print(\"LOC : str_param)\",str_param)\n",
        "        \n",
        "        # limit the search window\n",
        "        if pos > position_param and \\\n",
        "          (pos - position_param - len(str_param)) < 10 and \\\n",
        "          (pos - position_param - len(str_param)) > 0: \n",
        "          # print(\"LOC :\", val, pos - position_param - len(str_param))\n",
        "          return val\n",
        "\n",
        "      return return_str\n",
        "\n",
        "    def __find_preposition(self,\n",
        "                      position_param : int,\n",
        "                      str_param : str, \n",
        "                      dict_param : dict):\n",
        "      \n",
        "      \"\"\"\n",
        "        Description:\n",
        "            Search nearby preposition entity on the left side\n",
        "        Paramter:\n",
        "            position_param : int = postion of main entity\n",
        "            str_param : str = main enity\n",
        "            dict_param : dict = position and entity combination      \n",
        "        returns : \n",
        "            str : the first preposition found on the left side   \n",
        "      \"\"\"\n",
        "      return_str= \"\"\n",
        "\n",
        "      all_keywords = dict_param[\"Keywords\"]\n",
        "\n",
        "      try:\n",
        "        all_keywords.pop(\"ID\")\n",
        "      except:\n",
        "        # print(\"Cound not pop() ID\")\n",
        "        pass\n",
        "\n",
        "      for pos, val in sorted(all_keywords.items(), \n",
        "                              key= lambda kv: kv[0], reverse=True):\n",
        "        # print(\"Inside find_entity_of(), VALUE =\", \n",
        "        #       val, \"Pos:\", pos)\n",
        "          \n",
        "        if pos < position_param : # left side\n",
        "          # print(\"Inside find_preposition(), VALUE =\", val, pos)\n",
        "          for key in [\"from\", \"to\", \"partial\", \"full\"]:\n",
        "            for i in self.__imp_keywords_synonyms[key]:\n",
        "              if val == i: #match found\n",
        "                return key\n",
        "\n",
        "\n",
        "      return return_str     \n",
        "\n",
        "\n",
        "\n",
        "    def __find_entity_of(self,\n",
        "                      position_param : int,\n",
        "                      str_param : str, \n",
        "                      dict_param : dict):\n",
        "      \"\"\"\n",
        "        Description:\n",
        "            Search nearby enity on the left side\n",
        "        Paramter:\n",
        "            position_param : int = postion of main entity\n",
        "            str_param : str = main enity\n",
        "            dict_param : dict = position and entity combination      \n",
        "        returns : Dict of one entity, with prepositions\n",
        "      \"\"\"\n",
        "      return_dict : dict = None\n",
        "\n",
        "      all_keywords = dict_param[\"Keywords\"]\n",
        "\n",
        "      if all_keywords:\n",
        "\n",
        "        try:\n",
        "          all_keywords.pop(\"ID\")\n",
        "        except:\n",
        "          # print(\"Cound not pop() ID\")\n",
        "          pass\n",
        "\n",
        "        #Firstly search in Keywords\n",
        "        for pos, value in sorted(all_keywords.items(), \n",
        "                key = lambda kv: kv[0], reverse=True):\n",
        "          # print(\"Inside find_entity_of(), VALUE =\", value)\n",
        "            \n",
        "          # print(\"Looking entity for :\", str_param, \n",
        "          #       \"from position\", position_param)  \n",
        "          # print(\"Inside find_entity_of(), VALUE =\", value, pos)\n",
        "          if pos < position_param : # left side\n",
        "            if value == \"invoice\" and \\\n",
        "              \"{}\".format(str_param).find(\"/\") < 0:\n",
        "              return {\"RmtId\": str_param}\n",
        "            elif value == \"reference\":\n",
        "              return { \"RefNb\" : str_param}  \n",
        "            elif value == \"account\":\n",
        "              prep = self.__find_preposition(pos,\n",
        "                                                  value,\n",
        "                                                  dict_param) \n",
        "              if prep:\n",
        "                return {\n",
        "                    \"account_number\": str_param,\n",
        "                    \"preposition\": prep \n",
        "                        }\n",
        "              else:\n",
        "                return {\"account_number\": str_param}     \n",
        "\n",
        "            elif value in [\"fee\",\"tax\",\"credit\", \"debit\",\"due\",  \n",
        "              \"discount\"] and \"{}\".format(str_param).find(\"/\") < 0:\n",
        "              return { value : str_param }\n",
        "\n",
        "            elif value == \"bank\" and \"{}\".format(str_param).find(\"/\") < 0:\n",
        "              \n",
        "              #Next search in Banks     \n",
        "              # print(\"## Inside find_entity_of() \", dict_param)\n",
        "              banks = dict_param[\"Companies\"][\"Banks\"]\n",
        "\n",
        "              if banks:\n",
        "                for pos, value in sorted(banks.items(), \n",
        "                      key = lambda kv: kv[0], reverse=True):\n",
        "                  # print(\"Inside find_entity_of(), BANK =\", value, pos)\n",
        "                  if pos < position_param : # left side\n",
        "                      return { \"bank\" : value ,\n",
        "                              \"id\" : str_param }\n",
        "        \n",
        "\n",
        "\n",
        "            \n",
        "      # noting found\n",
        "      return return_dict\n",
        "\n",
        "\n",
        "    def __relate_org(self,\n",
        "                      # position_param : int,\n",
        "                      #  str_param : str, \n",
        "                      dict_param : dict):\n",
        "\n",
        "      \"\"\"\n",
        "        Description:\n",
        "          Find all Banks and Organizations, format, \n",
        "          add loacations, preositions \n",
        "        Parameter:\n",
        "          Dictionary : complete list  \n",
        "        Return: \n",
        "          Dictionary : formatted Oraganizations and Banks\n",
        "      \"\"\"       \n",
        "\n",
        "      if not dict_param[\"Companies\"]:\n",
        "        return None\n",
        "\n",
        "      return_list = []\n",
        "\n",
        "      for key, value in dict_param[\"Companies\"].items(): \n",
        "\n",
        "        if key == \"Banks\": \n",
        "          bank_dict_list = []\n",
        "          for p, v in value.items() :\n",
        "            if v.find(\"/\") < 0: # Bank name not to have / \n",
        "              bank_dict = { \"bank\" : v}\n",
        "\n",
        "              prep_dict = self.__find_preposition(\n",
        "                                p,v,dict_param)\n",
        "              if prep_dict:\n",
        "                bank_dict[\"preposition\"] = self.__find_preposition(\n",
        "                                                  p,v,dict_param)\n",
        "                \n",
        "              loc_dict = self.__find_locations(\n",
        "                                    p,v,dict_param) \n",
        "              if loc_dict:\n",
        "                bank_dict[\"location\"] = loc_dict\n",
        "\n",
        "              bank_dict_list.append(bank_dict)\n",
        "\n",
        "          if bank_dict_list: \n",
        "            return_list.extend(bank_dict_list)\n",
        "\n",
        "        else:\n",
        "          if value.find(\"/\") < 0: # Org name not to have / \n",
        "            org_dict = { \"organization\" : value}\n",
        "\n",
        "            loc_dict = self.__find_locations(key,value,dict_param)\n",
        "            if loc_dict:\n",
        "              org_dict[\"location\"] = loc_dict\n",
        "\n",
        "            prep_dict = self.__find_preposition(key,value,dict_param) \n",
        "            if prep_dict:\n",
        "              org_dict[\"preposition\"] = prep_dict\n",
        "\n",
        "            return_list.append(org_dict) \n",
        "              \n",
        "\n",
        "      return return_list                 \n",
        "\n",
        "\n",
        "\n",
        "    def __relate_entities(self, dict_param : dict, \n",
        "                          sentence_param : str):\n",
        "      \"\"\"\n",
        "        Description : Arrange entities in a sentence with relation, \n",
        "                      and returns one Invoice information structured\n",
        "        Parameters : \n",
        "          sentence_param : full text of one sentence\n",
        "          dict_param : dictionary of keywords \n",
        "        Return : \n",
        "          dict : Dictionary of one Invoice, per sentence   \n",
        "          bool : another_invoice_found \n",
        "      \"\"\"\n",
        "      another_invoice_found = False # tested with True\n",
        "\n",
        "      return_dict_list = []\n",
        "      # print(\"%%%%%%%% Inside relate_entities() %%%%%%%\") \n",
        "      # print(json.dumps(dict_param, indent=4, sort_keys=False)) \n",
        "      # print(\"***\", dict_param[\"Keywords\"])\n",
        "      keywords_dict = dict_param[\"Keywords\"]\n",
        "      remaining_dict = copy.deepcopy(dict_param)\n",
        "      # print(\"***\", keywords_dict)\n",
        "      ### Look for Invoice number:\n",
        "      if keywords_dict:\n",
        "        for key, values in keywords_dict.items():\n",
        "\n",
        "            # print(\"KEY=\",key)\n",
        "\n",
        "            if \"{}\".format(key) == \"ID\":\n",
        "              # print(\"> ID=\",values)\n",
        "                for pos_id ,id in values.items():\n",
        "\n",
        "                    # print(\"FIND : \", id, \", position:\",pos_id)\n",
        "                    found_dict = self.__find_entity_of(int(pos_id),\n",
        "                                                \"{}\".format(id), \n",
        "                                                remaining_dict)\n",
        "                    if found_dict:\n",
        "                      # print(\"Inside relate_entities(), found_dict\", \n",
        "                      #       found_dict)\n",
        "                      return_dict_list.append(found_dict)\n",
        "                      \n",
        "                      for result_key, result_values in found_dict.items(): \n",
        "                        if result_key == \"RmtId\":\n",
        "                          another_invoice_found = True\n",
        "                          # print(\"$$$ Keys\", remaining_dict[\"Keywords\"].keys())\n",
        "                          try: # match already found\n",
        "                            remaining_dict[\"Keywords\"].pop(\"invoice\") \n",
        "                          except:\n",
        "                            # print(\"Key invoice is not found\") \n",
        "                            pass\n",
        "                    # else:\n",
        "                    #    # No related entity found\n",
        "\n",
        "            elif \"{}\".format(values)==\"share\":  # else id ID  \n",
        "                print(\"$$$ SHARE VAL=\",values)\n",
        "                # for pos_id ,id in values.items():\n",
        "                # print(\"FIND : \", id, \", position:\",pos_id)\n",
        "                found_dict = self.__find_entity_of(int(key),\n",
        "                                \"{}\".format(values), remaining_dict)\n",
        "                if found_dict:\n",
        "                  return_dict_list.append(found_dict)\n",
        "                else:\n",
        "                  return_dict_list.append({\"unknown\": \"share\"})                       \n",
        " \n",
        "            else:\n",
        "              pass        \n",
        "\n",
        "\n",
        "      #Add amount\n",
        "      for m in dict_param[\"Money\"]:\n",
        "        found_related_entity = False\n",
        "        for key, val in m.items():\n",
        "          if key == \"position\":\n",
        "            found_dict = self.__find_entity_of(val,\n",
        "                                            m[\"amount\"], \n",
        "                                            dict_param)\n",
        "            if found_dict:\n",
        "              for result_key, result_values in found_dict.items():\n",
        "                \n",
        "                return_dict_list.append({\"Amt\" : m[\"amount\"],\n",
        "                                        \"Ccy\": m[\"currency\"],\n",
        "                                        \"related\": result_key}) \n",
        "                found_related_entity = True\n",
        "                break\n",
        "\n",
        "        if found_related_entity == False:\n",
        "          return_dict_list.append(m)\n",
        "\n",
        "      #Add URL\n",
        "      for u in dict_param[\"URLs\"]:\n",
        "          return_dict_list.append({\"URID\": u})           \n",
        "\n",
        "      #Add Contacts \n",
        "      # print(\"Contacts\", dict_param[\"Contacts\"])   \n",
        "      for cont in dict_param[\"Contacts\"]:\n",
        "        for key, val in cont.items():\n",
        "          if \"phone\" in key:\n",
        "            return_dict_list.append({\"PhneNb\": val})\n",
        "          elif \"name\" in key:\n",
        "            return_dict_list.append({\"Nm\": val})\n",
        "          # else:\n",
        "          #   # do not add ssn etc.   \n",
        "\n",
        "\n",
        "      #Add Dates\n",
        "      if dict_param[\"Dates\"]:\n",
        "        # print(\"DATES :\", dict_param[\"Dates\"])\n",
        "        for pos,dt_str in dict_param[\"Dates\"].items():\n",
        "          try:\n",
        "            datetime_val = parse(dt_str)\n",
        "            #Convert to String below\n",
        "            datetime_val = datetime_val.strftime(\"%m/%d/%Y, %H:%M:%S\")\n",
        "            found_dict = self.__find_entity_of(pos,\n",
        "                                        dt_str, \n",
        "                                        dict_param)\n",
        "            if found_dict:\n",
        "              for result_key, result_values in found_dict.items(): \n",
        "                  return_dict_list.append({\n",
        "                    \"date\" : datetime_val, \"related\" : result_key })\n",
        "                \n",
        "            else: # no related entity found\n",
        "                return_dict_list.append({\n",
        "                  \"RltdDt\" : datetime_val })\n",
        "\n",
        "          except: \n",
        "            # print(\"Could not parse Date\", dt_str)\n",
        "            pass\n",
        "\n",
        "      #Add Percents and Rates\n",
        "      if dict_param[\"Percents_Rates\"]:\n",
        "        # print(\"DATES :\", dict_param[\"Dates\"])\n",
        "        for per in dict_param[\"Percents_Rates\"]:\n",
        "          # print(\"PERCENTS AND RATES\",per)\n",
        "          # for type_str,val,pos in per.items():\n",
        "\n",
        "          type_str = per[\"type\"]\n",
        "          val = per[\"value\"]\n",
        "          pos = per[\"position\"]  \n",
        "\n",
        "          found_dict = self.__find_entity_of(pos,\n",
        "                                      type_str, \n",
        "                                      dict_param)\n",
        "          if found_dict:\n",
        "            for result_key, result_values in found_dict.items(): \n",
        "              return_dict_list.append({\n",
        "                    type_str : val, \"related\" : result_key })\n",
        "              \n",
        "          else: # no related entity found\n",
        "            return_dict_list.append({type_str : val })\n",
        "\n",
        "\n",
        "      org_list = self.__relate_org(dict_param)\n",
        "      if org_list:\n",
        "        return_dict_list.extend(org_list)   \n",
        "\n",
        "         \n",
        "\n",
        "\n",
        "      return return_dict_list, another_invoice_found\n",
        "\n",
        "    def __preprocess_contcatinated_entities(self,str_param : str):\n",
        "      \"\"\"\n",
        "        Description : \n",
        "        \n",
        "        Parameters : \n",
        "          str_param : the full string \n",
        "        Return : \n",
        "          str : \n",
        "      \"\"\"\n",
        "\n",
        "      if str_param.find(\"/\") < 0 or \\\n",
        "        str_param.find(\"http://\") >= 0 or \\\n",
        "        str_param.find(\"https://\") >= 0:\n",
        "        # no / found\n",
        "        return str_param\n",
        "\n",
        "      else:\n",
        "        # get all token words\n",
        "        tokens_list = lexnlp.nlp.en.tokens.get_token_list(str_param)\n",
        "\n",
        "        for word in tokens_list:\n",
        "          # find the token with /\n",
        "          # print(\"TOKEN\",word)\n",
        "          pos = word.find(\"/\") \n",
        "          if pos >=0:\n",
        "            str_whitespace = word.replace(\"/\", \" \")\n",
        "            pos_in_str = str_param.find(word)\n",
        "            \n",
        "            pre_word = str_param[:pos_in_str]\n",
        "            # print(\"Pre-Word\",pre_word)\n",
        "            post_word = str_param[pos_in_str:]\n",
        "            # print(\"Post-word\", post_word)\n",
        "            # append the new words after the original word\n",
        "            str_param =  pre_word + \\\n",
        "            \" \" + str_whitespace + \" \" + post_word\n",
        "\n",
        "\n",
        "        return str_param      \n",
        "\n",
        "    def structure_invoice(self,str_param : str):\n",
        "      \"\"\"\n",
        "        Description : identify all important keywords, \n",
        "                      and returns Invoice information JSON\n",
        "        Parameters : \n",
        "          str_param : the full string \n",
        "        Return : Array of Dictionaies, each on one Invoice\n",
        "      \"\"\"\n",
        "      return_dict_list = []\n",
        "      one_invoice = {}\n",
        "\n",
        "      str_param = self.__preprocess_contcatinated_entities(\n",
        "                        str_param)\n",
        "      # print(\"Going to process : \", str_param)\n",
        "\n",
        "      ls_sentences = list( \n",
        "      lexnlp.extract.en.entities.nltk_re.get_sentence_span_list(str_param))\n",
        "      # print(\"ALL SENTENCES\", ls_sentences)\n",
        "\n",
        "      sentence_num = 0\n",
        "      invoice_num = 0\n",
        "      for strat,end,sentence in ls_sentences:\n",
        "        \n",
        "        keywords_dict = self.__identify_all_keywords(sentence) \n",
        "        # print(\"@@@\",json.dumps(keywords_dict, indent=4, sort_keys=False)) \n",
        "        \n",
        "        structured_dict, another_invoice_found = \\\n",
        "          self.__relate_entities(keywords_dict, sentence)\n",
        "        # print(\"[] Inside structure_invoice():\", structured_dict)\n",
        "\n",
        "        if structured_dict:\n",
        "          # take last invoice and extend\n",
        "          if len(return_dict_list) > 0 :\n",
        "              invoice_dict_list = []\n",
        "              invoice_dict = {}\n",
        "              try:\n",
        "                invoice_dict_list = return_dict_list[ \n",
        "                  len(return_dict_list) -1 ].pop(str(invoice_num))\n",
        "\n",
        "                invoice_dict_list.extend(structured_dict)\n",
        "\n",
        "                return_dict_list[len(return_dict_list) -1] = \\\n",
        "                  {str(invoice_num) : invoice_dict_list}\n",
        "              except: # Invoice number is increamented\n",
        "                # print(\"Could not pop()\",invoice_num)\n",
        "                return_dict_list.append(\n",
        "                    {str(invoice_num) : structured_dict})\n",
        "\n",
        "          else:\n",
        "              return_dict_list = [{invoice_num : structured_dict}]\n",
        "\n",
        "        if another_invoice_found == True:\n",
        "          invoice_num = invoice_num + 1\n",
        "          # print(\"INVOICE # :\", invoice_num)     \n",
        "            \n",
        "\n",
        "        sentence_num = sentence_num + 1\n",
        "        # print(\"Sentence ends \",str(sentence_num), \"-\" * 70)\n",
        "\n",
        "\n",
        "      return return_dict_list\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DarWd_ojwSNP"
      },
      "source": [
        "# ##### TESTING\n",
        "\n",
        "# \"\"\"\n",
        "   \n",
        "# Env-ABC/4562/2015-09-08/DEF Electronics, London/10 mln JPY/To account 23683707994215 with AAAA Bank, London (AAAAGB2L).\n",
        " \n",
        "# Scenario: An invoice with number 4562, dated 08 September 2015 from DEF Electronics, London: 10 million JPY needs to be paid to DEF Electronics account 23683707994215 with AAAA Bank, London (AAAAGB2L). \n",
        "# ABC Corporation assigns reference ABC/4562/2015-09-08 to the payment. Payment transaction charges are shared between ABC Corporation and DEF Electronics.\n",
        " \n",
        "# Invoise-ABC/ABC-13679/2015-09-15/GH Semiconductor Brussels/50k EURO for act BE30001216371411 DDDD Bank, Belgium (DDDDBEBB)\n",
        " \n",
        "# Scenario : An invoice with number ABC-13679, dated 15 September 2015 from GHI Semiconductors, Brussels: 500,000 EUR needs to be paid to GHI Semiconductors account BE30001216371411 with DDDD Bank, Belgium (DDDDBEBB). \n",
        "# ABC Corporation assigns reference ABC/ABC-13679/2015-09-15 to the payment. \n",
        "# The accounts receivable department of GHI Semiconductors needs to be advised when the funds have been credited to the account on telephone number +32/2/2222222. \n",
        "# GHI Semiconductors will bear all payment transaction charges.\n",
        " \n",
        "# Agnst Inv - ABC/987-AC/2015-09-27/1 milin USD/chg shared\n",
        "\n",
        "# Scenario : An invoice with number 987-AC, dated 27 September 2015 from their branch ABC Corporation, California: 1 million USD needs to be paid on the branch account 4895623 with BBBB Bank, San Francisco (BBBBUS66). \n",
        "# ABC assigns reference ABC/987-AC/2015-09-27 to the payment. Payment transaction charges are shared.\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "# text =   \"Biogenetics-Crops, Glasgow, subsidiary of Biogenetics HQ, London, has received an invoice with number SX-25T, dated 13 October 2010 from Seed Inc., Dublin: 75 thousand EUR needs to be paid to the account of Seed Inc. IE29CCCC93115212345678 held at CCCC Bank, Dublin (CCCCIE2D). Transaction charges for the payment are shared between Biogenetics and Seed Inc. The payment of all Biogenetics invoices is centralised at Biogenetics HQ. It assigns reference CROPS/SX-25T/2015-10-13 to the payment order and passes it on to AAAA Bank (AAAAGB2L) where it holds the account 46373892034012. AAAA Bank sends the payment to its correspondent BBBB Bank in Dublin (BBBBIE2D).\"\n",
        "\n",
        "# example = text + \" Fees is 5%.\"\n",
        "\n",
        "# test_texts = [\n",
        "#               \"Remit ID 999666, amt INR 350, credit to Wipro Ltd., Bangalore, phone 800-400-1234 or (860) 442-1234, dated July 06 2020.\",\n",
        "#               example,\n",
        "#               \"Inv 12345678 paid, dated Aug-15-2017 amount $234, tax $5.50, from Bank of America, to Chase Bank, New York. Inv# abc-123 due amont 500 USD, fees 1%, credit  $495. Remit URL is https:\\\\www.example.com\",\n",
        "#               \"Inv ABC/4562/2015-09-08/DEF Electronics Inc., London/10 million JPY/To account 23683707994215 with AAAA Bank, London (AAAAGB2L)\",\n",
        "#               \"Invoice/ABC-13679/2015-09-15 GH Semiconductor Brussels/50k EURO for act BE30001216371411 DDDD Bank, Belgium (DDDDBEBB00)\",\n",
        "#               \"Agnst Inv - ABC/987-AC/2015-09-27/1 mm USD/chg shared\"\n",
        "#               ] \n",
        "\n",
        "# for t in test_texts:\n",
        "#   print(\"// \",\"=\" * 80)\n",
        "#   print(\"// Testing the parsing of:'\",t,\"'\")\n",
        "#   print(\"// \",\"=\" * 80)\n",
        "#   parser = CreditTransferTextParserNLP()\n",
        "#   # print(\"PRE-PROCESSING:\", parser.preprocess_contcatinated_entities(t))\n",
        "#   payment_dict = parser.structure_invoice(t)\n",
        "#   # paymennt_dict\n",
        "#   for i in payment_dict:\n",
        "#     print(\"// One Invoice (Remit)\", \"-\"*50)\n",
        "#     print(json.dumps(i, indent=4, sort_keys=False)) "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0N1YS_2FP036",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f025ce63-5722-4a49-a6ef-f1da25fe0c1e"
      },
      "source": [
        "\n",
        "  \n",
        "\n",
        "with os.scandir(\n",
        "  \"/content/drive/MyDrive/Banking-Solutions/B2B-Payment\") as entries:\n",
        "\n",
        "    for entry in entries:\n",
        "      print( \"// XML File =\", entry.path)\n",
        "      with open(\n",
        "        \"/content/drive/MyDrive/Banking-Solutions/\" + \n",
        "        entry.name[:entry.name.find(\".\")] + \".JSON\", \n",
        "        'w') as f:\n",
        "\n",
        "        # tree = None\n",
        "        tree = et.parse(entry.path)\n",
        "        root = tree.getroot()\n",
        "        unstructured_text_ele = root.find(\n",
        "            \"./CdtTrfTxInf/RmtInf/Ustrd\")\n",
        "        # print(unstructured_text_ele.text)\n",
        "\n",
        "        un_text =  unstructured_text_ele.text\n",
        "        un_text = un_text.strip()\n",
        "        print(\"// \",\"=\" * 80)\n",
        "        print(\"// Testing the parsing of:'\",un_text,\"'\")\n",
        "        print(\"// \",\"=\" * 80)\n",
        "        # f.write(\"// The parsing of:'\" + un_text +\"'\\n\")\n",
        "\n",
        "        parser = CreditTransferTextParserNLP()\n",
        "        # print(\"PRE-PROCESSING:\", \n",
        "        # parser.preprocess_contcatinated_entities(t))\n",
        "        payment_dict = parser.structure_invoice(un_text)\n",
        "        # paymennt_dict\n",
        "        count = 0\n",
        "        for i in payment_dict:\n",
        "          count = count + 1\n",
        "          print(\"// One Invoice (Remit)\", \"-\"*50)\n",
        "          print(json.dumps(i, indent=4, sort_keys=False))\n",
        "          if count > 1:\n",
        "            f.write(\",\"+json.dumps(i, indent=4, sort_keys=False))\n",
        "          else:\n",
        "            f.write(\" \\n[\"+json.dumps(i, indent=4, sort_keys=False)) \n",
        "\n",
        "        f.write(\"]\")\n",
        "            \n",
        "\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "// XML File = /content/drive/MyDrive/Banking-Solutions/B2B-Payment/Sample-2-pacs-008.xml\n",
            "//  ================================================================================\n",
            "// Testing the parsing of:' Biogenetics-Crops, Glasgow, subsidiary of Biogenetics HQ, London, has received an invoice with number SX-25T, dated 13 October 2010 from Seed Inc., Dublin: 75 thousand EUR needs to be paid to the account of Seed Inc. IE29CCCC93115212345678 held at HSBC Bank, Dublin (HSBCIE2D). Transaction charges for the payment are shared between Biogenetics and Seed Inc. The payment of all Biogenetics invoices is centralised at Biogenetics HQ. It assigns reference CROPS/SX-30T/2015-10-13 to the payment order and passes it on to TD Bank (TD00562L) where it holds the account 46373892034012. TD Bank sends the payment to its correspondent HSBC Bank in Dublin (BBBBIE2D). Fees is 5%. '\n",
            "//  ================================================================================\n",
            "$$$ SHARE VAL= share\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"0\": [\n",
            "        {\n",
            "            \"RmtId\": \"SX-25T\"\n",
            "        },\n",
            "        {\n",
            "            \"account_number\": \"IE29CCCC93115212345678\",\n",
            "            \"preposition\": \"to\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"id\": \"HSBCIE2D\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 75000.0,\n",
            "            \"Ccy\": \"EUR\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"date\": \"10/13/2010, 00:00:00\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"Biogenetics HQ\",\n",
            "            \"location\": \"London\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"Seed Inc.\",\n",
            "            \"location\": \"Dublin\",\n",
            "            \"preposition\": \"from\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"Seed Inc. IE29CCCC93115212345678\",\n",
            "            \"preposition\": \"to\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"preposition\": \"to\",\n",
            "            \"location\": \"Dublin\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"1\": [\n",
            "        {\n",
            "            \"unknown\": \"share\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"Biogenetics and Seed Inc.\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"Biogenetics\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"Biogenetics HQ\"\n",
            "        },\n",
            "        {\n",
            "            \"RefNb\": \"SX-30T\"\n",
            "        },\n",
            "        {\n",
            "            \"RefNb\": \"CROPS/SX-30T/2015-10-13\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"TD Bank\",\n",
            "            \"id\": \"TD00562L\"\n",
            "        },\n",
            "        {\n",
            "            \"account_number\": \"46373892034012\",\n",
            "            \"preposition\": \"to\"\n",
            "        },\n",
            "        {\n",
            "            \"date\": \"10/13/2015, 00:00:00\",\n",
            "            \"related\": \"RefNb\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"TD Bank\",\n",
            "            \"preposition\": \"to\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"id\": \"BBBBIE2D\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"TD Bank\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"preposition\": \"to\",\n",
            "            \"location\": \"Dublin\"\n",
            "        },\n",
            "        {\n",
            "            \"%\": 5.0,\n",
            "            \"related\": \"fee\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// XML File = /content/drive/MyDrive/Banking-Solutions/B2B-Payment/Sample-4-pacs-008.xml\n",
            "//  ================================================================================\n",
            "// Testing the parsing of:' Inv ABC/4562/2015-09-08/DEF Electronics Inc., London/10 million JPY/To account 23683707994215 with HSBC Bank, London (HSBC-GB2L) '\n",
            "//  ================================================================================\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"0\": [\n",
            "        {\n",
            "            \"RmtId\": \"4562\"\n",
            "        },\n",
            "        {\n",
            "            \"account_number\": \"23683707994215\",\n",
            "            \"preposition\": \"to\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"id\": \"HSBC-GB2L\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 10000000.0,\n",
            "            \"Ccy\": \"JPY\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"date\": \"09/08/2015, 00:00:00\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"DEF Electronics Inc.\",\n",
            "            \"location\": \"London\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"HSBC\",\n",
            "            \"preposition\": \"to\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"preposition\": \"to\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// XML File = /content/drive/MyDrive/Banking-Solutions/B2B-Payment/Sample-6-pacs-008.xml\n",
            "//  ================================================================================\n",
            "// Testing the parsing of:' Agnst Inv - ABC/987-AC/2015-09-27/1 mm USD/chg shared '\n",
            "//  ================================================================================\n",
            "$$$ SHARE VAL= share\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"0\": [\n",
            "        {\n",
            "            \"fee\": \"share\"\n",
            "        },\n",
            "        {\n",
            "            \"RmtId\": \"987-AC\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 1000000.0,\n",
            "            \"Ccy\": \"USD\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"date\": \"09/27/2015, 00:00:00\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"ABC\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// XML File = /content/drive/MyDrive/Banking-Solutions/B2B-Payment/Sample-5-pacs-008.xml\n",
            "//  ================================================================================\n",
            "// Testing the parsing of:' Invoice/ABC-13679/2015-09-15 GH Semiconductor Brussels/50k EURO for act BE30001216371411 at HSBC Bank, Belgium DDDDBEBB00. '\n",
            "//  ================================================================================\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"0\": [\n",
            "        {\n",
            "            \"RmtId\": \"ABC-13679\"\n",
            "        },\n",
            "        {\n",
            "            \"account_number\": \"BE30001216371411\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"id\": \"DDDDBEBB00\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 50000.0,\n",
            "            \"Ccy\": \"EUR\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"date\": \"09/15/2015, 00:00:00\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"GH Semiconductor\",\n",
            "            \"location\": \"Brussels\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"HSBC Bank\",\n",
            "            \"location\": \"Belgium\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// XML File = /content/drive/MyDrive/Banking-Solutions/B2B-Payment/Sample-1-pacs-008.xml\n",
            "//  ================================================================================\n",
            "// Testing the parsing of:' Remit ID 999666, amt INR 850, credit to Wipro Ltd., Bangalore, phone 800-400-1234 or (888) 442-1234, dated July 06 2020, from SBI Bank. '\n",
            "//  ================================================================================\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"0\": [\n",
            "        {\n",
            "            \"RmtId\": \"999666\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 850.0,\n",
            "            \"Ccy\": \"INR\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"PhneNb\": \"(800) 400-1234\"\n",
            "        },\n",
            "        {\n",
            "            \"PhneNb\": \"(888) 442-1234\"\n",
            "        },\n",
            "        {\n",
            "            \"date\": \"07/06/2020, 00:00:00\",\n",
            "            \"related\": \"credit\"\n",
            "        },\n",
            "        {\n",
            "            \"organization\": \"Wipro Ltd.\",\n",
            "            \"location\": \"Bangalore\",\n",
            "            \"preposition\": \"to\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"SBI Bank\",\n",
            "            \"preposition\": \"from\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// XML File = /content/drive/MyDrive/Banking-Solutions/B2B-Payment/Sample-3-pacs-008.xml\n",
            "//  ================================================================================\n",
            "// Testing the parsing of:' Inv 12345678 paid, dated Aug-15-2017 amount $234, tax $5.50, from Bank of America, to Chase Bank, New York. Inv# abc-123 due amont 500 USD, fees 1%, credit  $495. URL is https://www.example.com. '\n",
            "//  ================================================================================\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"0\": [\n",
            "        {\n",
            "            \"RmtId\": \"12345678\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 234.0,\n",
            "            \"Ccy\": \"USD\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 5.5,\n",
            "            \"Ccy\": \"USD\",\n",
            "            \"related\": \"tax\"\n",
            "        },\n",
            "        {\n",
            "            \"date\": \"08/15/2017, 00:00:00\",\n",
            "            \"related\": \"RmtId\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"Bank of America\",\n",
            "            \"preposition\": \"from\"\n",
            "        },\n",
            "        {\n",
            "            \"bank\": \"Chase Bank\",\n",
            "            \"preposition\": \"to\",\n",
            "            \"location\": \"New York\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"1\": [\n",
            "        {\n",
            "            \"RmtId\": \"abc-123\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 500.0,\n",
            "            \"Ccy\": \"USD\",\n",
            "            \"related\": \"due\"\n",
            "        },\n",
            "        {\n",
            "            \"Amt\": 495.0,\n",
            "            \"Ccy\": \"USD\",\n",
            "            \"related\": \"credit\"\n",
            "        },\n",
            "        {\n",
            "            \"%\": 1.0,\n",
            "            \"related\": \"fee\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "// One Invoice (Remit) --------------------------------------------------\n",
            "{\n",
            "    \"2\": [\n",
            "        {\n",
            "            \"URID\": \"https://www.example.com\"\n",
            "        }\n",
            "    ]\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGxQEd3XP1AX"
      },
      "source": [
        ""
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMJ5Cg3RP1I1"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYOzXOwpP1LX"
      },
      "source": [
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jj2ESiDZDSVk"
      },
      "source": [
        "\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxmdLVYnbIAv"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpDT8uEkG3TP"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    }
  ]
}